<!DOCTYPE html>
<html>
  <head>
    <title>HTM on AP Update 2015-08-03</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">
      @import url(http://fonts.googleapis.com/css?family=Droid+Serif);
      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);

      body {
        font-family: 'Droid Serif';
        font-size: 20px;
      }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: 400;
        margin-bottom: 0;
      }
      h1 { font-size: 4em; }
      h2 { font-size: 2em; }
      h3 { font-size: 1.6em; }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      li p { line-height: 1.25em; }
      .red { color: #fa0000; }
      .large { font-size: 2em; }
      a, a > code {
        color: rgb(249, 38, 114);
        text-decoration: none;
      }
      code {
        -moz-border-radius: 5px;
        -web-border-radius: 5px;
        background: #e7e8e2;
        border-radius: 5px;
        font-size: 16px;
      }
      .pull-left {
        float: left;
        width: 47%;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: #272822;
        color: #777872;
        text-shadow: 0 0 20px #333;
      }
      .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 0.8em;
      }

      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        font-size: 0.9em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }

      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
        .left-column h2:last-of-type, .left-column h3:last-child, .left-column h5:last-child {
          color: #000;
        }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 2em;
      }

      /* Images */
      .image-240h img {
        height: 240px;
      }

      .image-420h img {
        height: 420px;
      }

      .image-480h img {
        height: 480px;
      }

      .image-320w img {
        width: 320px;
      }

      .image-720w img {
        width: 720px;
      }

      .image-centered img {
        display: block;
        margin-left: auto;
        margin-right: auto;
      }
    </style>
  </head>
  <body onload="var slideshow = remark.create();">
    <textarea id="source">
name: inverse
layout: true
class: center, middle, inverse

---

# Hierarhical Temporal Memory on the Automata Processor

Mateja Putic

AJ Varshneya

---

background-image: url(http://41.media.tumblr.com/tumblr_ltyk3fYnNn1r0i205o1_1280.jpg)
class: center, middle, inverse

---

background-image: url(http://41.media.tumblr.com/tumblr_ltyk3fYnNn1r0i205o1_1280.jpg)
class: center, middle, inverse

# It Works!

---

layout: false

# Overview

- **Problem Definition**

- Evaluation Criteria

- Proposed Solution

- Conclusions

- Next Steps

---

# Background

- Developing AI applications requires domain knowledge, significant programmer effort

- HTM captures principles by which the neocortex is a universal learning machine

- Dynamic data analytics require inference model changes as patterns change

- An efficient implementation of HTM is valuable

- Long term goal: Speed up HTM learning

- Short term goal: Speed up inference

---

# Background

- What is HTM?

- What is the computation model of HTM?

---

# Background

- What is HTM?

- What is the computation model of HTM?

# Research Questions

- Where are the top bottlenecks?

- What is an efficient mapping of HTM execution to the AP?

---

# Evaluation Criteria

- Speedup: Can we capture significant speedups in HTM inference, learning?

- Scalability: Can speedups enable simulation of bigger HTMs?

- Applications: What applications will be enabled by faster, bigger HTMs?

---

# What is HTM?

## Basics

- Prediction / anomaly detection framework for temporal data

- Learns temporal sequences and performs inference at the same time

- Based on neural networks, cell-based computation model

.image-centered[
  .image-240h[![](static/Neuron_vs._basic_HTM_cell.bmp)]
]

---

# What is HTM?

## What kind of applications run on HTM?

- Server monitoring (Grok)

- Rogue behavior detection

- Stock volume anomalies

- Geospatial tracking

- Natural language search / prediction (cortical.io)

- Good fit for applications with data where order matters

---

# Baseline HTM Stack

.image-centered[
  .image-480h[![](static/HTM_stack_diagram.png)]
]

---

# HTM Computation Model

- Uses Sparse Distributed Representations (SDRs)

- Wide binary vector with few 1's (typically about 2%), mostly 0's

- Interesting properties:
  
  - **Similarity**: Bit overlap between SDRs is used to determine similarity

  - **Store and compare**: Only active indices of bits are stores, comparing only a subset of stored bits is OK

  - **Union Membership**: High probability that original SDR can be retrieved from a union of SDRs

- Data format that is highly resilient to bit errors

---

background-image: url(static/Slide4.PNG)
class: center

---

background-image: url(static/Slide5.PNG)
class: center, middle

---

background-image: url(static/Slide6.PNG)
class: center, middle

---

background-image: url(static/Slide7.PNG)
class: center, middle

---

background-image: url(static/Slide9.PNG)
class: center, middle

---

# Preliminary Study

.image-centered[
  .image-720w[![](static/kcachegrind_output.png)]
]

---

# Preliminary Study

## Where are the bottlenecks?

- 81% of time is spent in `getSegmentActivityLevel`

  - Part of cell activation

  - With 65,536-cell model, called 97 million times

- Next highest is `lambda` call

  - Selects winning columns

---

# NuPIC Bottleneck Kernels

`getSegmentActivityLevel` in temporal pooler

```cpp
for (Py_ssize_t i = 0; i < n; ++i) {
  nupic::py::List syn;
  syn.assign(seg.fastGetItem(i));
  nupic::Real32 p = (nupic::Real32) PyFloat_AsDouble(syn.fastGetItem(2));
  if (p >= connectedPerm) {
    nupic::UInt32 c = (nupic::UInt32) PyLong_AsLong(syn.fastGetItem(0));
    nupic::UInt32 j = (nupic::UInt32) PyLong_AsLong(syn.fastGetItem(1));
    activity += state[c * stride0 + j];
  }
}
```

1. For each synapse on the segment:
  1. Get the state of the synapse
  1. If the permanence of the synapse is above threshold:
      1. Get the column, cell indices of the source cell
      1. Add its activity to the running total

---

# NuPIC Bottleneck Kernels

`_inhibitColumnsGlobal` in spatial pooler

```python
numActive = int(density * self._numColumns)
activeColumns = numpy.zeros(self._numColumns)
winners = sorted(range(overlaps.size),
                 key=lambda k: overlaps[k],
                 reverse=True)[0:numActive]
activeColumns[winners] = 1
return numpy.where(activeColumns > 0)[0]
```

1. Sort columns by overlap score
2. Pick the top k winners

---

# Preliminary Study Results

- Spatial Pooler: k-winners take all

- Temporal Pooler: Thresholded Hamming weight

- What do these algorithms have in common?

  -  Winners picked based on score beyond some threshold

- Why does this hit a von Neumann pain point?

  - Quad-nested for loop with random access memory

- How much speedup could we capture?

  - With bottleneck kernels ~90% of runtime, potential ~10X speedup

---

# Overview

- Problem Definition

- Evaluation Criteria

- **Proposed Solution**

- Results

- Limitations

- Broad Impacts

---

# Idea

- Column, cell activations could be computed using counters

- Can we use the AP's massive parallelism but limited computational capabilities to efficiently compute activations?

- Can we exploit the robustness property of SDRs to more efficiently compute column, cell activations on the AP with a small loss in accuracy?

- *Approximate* k-Winners Take All (kWTA) algorithm to implement column selection

  - Collect statistics to calculate thresholds

- Temporal pooler already uses activation threshold

---

# Minimum Viable Prototype

## Would the thresholding approach work on the baseline algorithm?

- Train HTM with kWTA column activation

- Turn off learning, run inference and collect overlap counts for each column that led to activation

- Find thresholds for each column where cumulative overlap score is maximized

- Replace sort-based kWTA algorithm (`lambda` call) with threshold-based column activation

- Re-run inference, compare the outputs

---

# MVP Results: Hotgym

.image-centered[
  .image-420h[![](static/energy_usage_prediction_chart.png)]
]

Baseline vs. threshold-based activation: correlates 99%!

---

# Building an AP model toolchain

## HTM to AP synthesizer

  - Takes a trained HTM and converts to ANML

## HTM parameter dumper

 - Takes a trained HTM, produces data structure with all parameter necessary to construct AP model

## HTM data portability

 - Converts between HTM outputs/AP inputs and vice versa

---

# HTM-AP Stack

.image-centered[
  .image-420h[![](static/AP_HTM_stack_diagram.png)]
]

---
# AP Model Synthesizer
- Synthesizer generates an AP Model for an HTM

- ANML macros linked together in layers, encapsulated in top-level file

- Synthesizer generates model from ANML templates, populated with Python/Jinja2

???

- Going to talk about:
  - Synthesizer
  - Aspects of our AP Model
- High level:
  - Generates ANML macros which represent a trained HTM
  - Using Python/Jinja2 to populate templates

---
# AP Model Synthesizer

- Inputs: HTM Architectural Parameters

- Outputs: ANML for HTM model

![](static/code_snippets.png "")

???

Synthesizer takes HTM params and generates ANML for HTM

---
# Hierarchy

![](static/hierarchy.png "")

---
# Execution
- Two phases of execution
    - Spatial Pooler (SP)
    - Temporal Memory (TM)

- Control characters:
    - \xfd, \xfe, and \xff

???
Control characters signal phases

---
# Execution
Input Tape:


 **\xff { SDR active bit indices } \xff { Active cell indices } \xfd \xfe \xff**



| **Pattern** | **Use**  |
|------------ |---------- |
| \xff| start of SP phase |
| SDR active bit indices   | sufficient matches -> activate column |
| \xff| end of SP phase, start of TM phase |
| Active cell indices&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | sufficient matches -> activate cell |
| \xfd   | report which cells activated |
| \xfe   | check if bursting occurred |
| \xff   | end of TM phase |

???

sufficient overlaps between synapses, SDR -> activate column

sufficient activated cells firing that predict a cell -> activate cell

---
.left-column[
  ## Baseline AP Model
  ##### Temporal Memory Segment
]
.right-column[
##### Counts connected cell activations, determines whether a cell should activate

![](static/tm_segment.png "")

]
???

Count number of cells that predict this one in the previous timestep to decide whether to activate this cell

---
.left-column[
  ## Baseline AP Model
  ##### Temporal Memory Segment
  ##### Temporal Memory Cell

]

.right-column[
##### Encapsulates TM segments

  ![](static/cell.png)


]

???
Lumps segments for a particular cell


---

.left-column[
  ## Baseline AP Model
  ##### Temporal Memory Segment
  ##### Temporal Memory Cell
  ##### Temporal Memory Column
]

.right-column[
##### Implements bursting logic, cell activation reporting

  ![](static/tm_column.png)

]

???

- Top STEs implement the bursting logic
- Burst if column was activated by SP and no cell activated

---
.left-column[
  ## Baseline AP Model
  ##### Temporal Memory Segment
  ##### Temporal Memory Cell
  ##### Temporal Memory Column
  ##### Spatial Pooling Segment

]

.right-column[
##### Counts connected SDR indices, determines whether a column should activate

  ![](static/sp_segment.png "")

]

???

Same structure as TM segment except for reset 
# 
---
.left-column[
  ## Baseline AP Model
  ##### Temporal Memory Segment
  ##### Temporal Memory Cell
  ##### Temporal Memory Column
  ##### Spatial Pooling Segment
  ##### HTM Column
]

.right-column[
##### Represents full HTM column with spatial pooler and temporal memory functions; implements logic to control phases of execution

  ![](static/htm_column.png "")


]

???

- STEs on the left act as a program counter, control phases
- STEs in the middle are another instance of this 1-bit memory pattern

---
.left-column[
  ## Baseline AP Model
  ##### Temporal Memory Segment
  ##### Temporal Memory Cell
  ##### Temporal Memory Column
  ##### Spatial Pooling Segment
  ##### HTM Column
  ##### HTM Region

]

.right-column[
##### Top-level file; collection of HTM Columns

![](static/htm_region.png "")
]

---
# Two-step Model
- Problem: number of parallel matches limited by STE symbol size (256 symbols max!)

- Tradeoff performance/size of design to increase alphabet size

- Two-step model can match 65536 (2<sup>16</sup>) symbols

---
.left-column[
  ## Two-step AP Model
  ##### Keeper Pattern
]

.right-column[
##### Activates an element until special character encountered
![](static/keeper_xff_xfd.png "")

| input       | behavior  |
|------------ |---------- |
| ^\xff^\xfd&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | continue  |
| ^\xff&nbsp;&nbsp;\xfd   | continue  |
| &nbsp;&nbsp;\xff^\xfd   | continue  |
| &nbsp;&nbsp;\xff&nbsp;&nbsp;\xfd    | stop      |
]

---
.left-column[
  ## Two-step AP Model
  ##### Keeper Pattern
  ##### Matcher Pattern
]
.right-column[
  ##### Activates an element when special character encountered
  ![](static/matcher_xff_xfd.png "")

]

---
.left-column[
  ## Two-step AP Model
  ##### Keeper Pattern
  ##### Matcher Pattern
  ##### Temporal Memory Segment
]

.right-column[
  ##### Multiple STEs to match on cell activations

  ![](static/tm_segment_2step.png)
]

---
.left-column[
  ## Two-step AP Model
  ##### Keeper Pattern
  ##### Matcher Pattern
  ##### Temporal Memory Segment
  ##### Temporal Memory Cell
]

.right-column[
##### Same as baseline model
![](static/cell.png)
]

---
.left-column[
  ## Two-step AP Model
  ##### Keeper Pattern
  ##### Matcher Pattern
  ##### Temporal Memory Segment
  ##### Temporal Memory Cell
  ##### Temporal Memory Column
]

.right-column[
##### Same structure, but uses keeper/matcher elements

![](static/tm_column_2step.png)
]
---
.left-column[
  ## Two-step AP Model
  ##### Keeper Pattern
  ##### Matcher Pattern
  ##### Temporal Memory Segment
  ##### Temporal Memory Cell
  ##### Temporal Memory Column
  ##### Spatial Pooling Segment
]

.right-column[
##### Multiple STEs to match on SDR bit indices

![](static/sp_segment_2step.png)
]
---
.left-column[
  ## Two-step AP Model
  ##### Keeper Pattern
  ##### Matcher Pattern
  ##### Temporal Memory Segment
  ##### Temporal Memory Cell
  ##### Temporal Memory Column
  ##### Spatial Pooling Segment
  ##### HTM Column
]

.right-column[
##### Same structure, but uses keeper/matcher elements

![](static/htm_column_2step.png)
]

---
# AP Model Next Steps
- Test multiple input cycles on single HTM
- Connecting multiple regions into layers
- Optimizations

???

1. We tested this on smaller models but not on larger ones
2. Would allow us to maybe do something like audio/video or other more complicated models
3. Can probably use fewer STEs than what we are currently using, especially in the segments

---

# MVP Results: Hotgym

.image-centered[
  .image-420h[![](static/energy_usage_prediction_chart_ap_results.png)]
]

---

# Complexity

- Time

  - Average case, 2% of input, cells are active in each HTM symbol cycle

  - s = width of input SDR, c = cols, i = cells per col, j = seg per cell, k = synapses per seg 

  - &Theta;(2 &#xb7; (5 + (c &#xb7; i &#xb7; 0.02) + (s &#xb7; 0.02)))

  - Grows linearly with the size of the input, number of cells

  - Compare to von Neumann &Theta;(c &#xb7; i &#xb7; j &#xb7; k)

  - AP does not have to inspect each synapse

---

# Complexity

- Space

  - STEs: &Theta;(c<sup>2</sup> &#xb7; i<sup>2</sup> &#xb7; j)

  - Counters: &Theta;(c &#xb7; i &#xb7; j)

  - Inverters: &Theta;(c)

  - Many cells will be pruned during learning, reducing size of design

---

# Static Resource Utilization

- Node counts

  - STEs: 777,755

  - Counters: 13,799

  - Inverters: 776

- Fan-in maximums

  - STEs: 89 (3)

  - Counters: 255 (1)

  - Inverters 1 (776)

- Fan-out maximums

  - STEs: 2028 (1)

  - Counters: 5 (13411), Inverters: 30 (2)

---

# HTM Elements: Hotgym

- Columns: 389

- Total cells: 7270

- Total segments: 13412

---

# Speedup: Hotgym

- Time

  - For our design, 2 &#xb7; (5 + 7270 &#xb7; 0.02 + 2048 &#xb7; 0.02) = 675

  - Assuming 100 MHz clock, one symbol cycle completes in 6.75 us, regardless of size of HTM

  - Actual speedup vs. von Neumann is future work

---

# Conclusions

- Approximate column activation algorithm exploits robustness property of HTM

- The MISD organization of the AP enables high degree of parallelism

- Runtime is sensitive to total number of cells, not number of segments or synapses

- HTM size could be limited by the number of counters

---

# Next Steps

- Functional model working, need to do more thorough performance evaluation

- Determine routing requirements of the design with AP compiler

- Size optimizations of two-step HTM cell design

- More compact input representation

- Learning!

- How does a loss of fidelity affect other HTM applications?

---

class: center, middle, inverse

# Thank you.
## Questions?

Slideshow created using [remark](http://github.com/gnab/remark).
    </textarea>
    <!-- <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js"></script> -->
<!-- load remark -->
<script src="http://gnab.github.com/remark/downloads/remark-0.5.1.min.js" type="text/javascript"></script>

<!-- load MathJax -->
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&delayStartupUntil=configured"></script>

<!-- Initialize (has to go in <script> tag **without** SRC attribute) -->
<script type="text/javascript">
    // Create slideshow
    var slideshow = remark.create({
        // This BREAKS MathJax: 
        // highlightLanguage: 'Python'
    
        // You have to tag every code block with python, like so:
        //
        // ```python
        // def add(a, b):
        //     return a + b
        // ```
        
    });
    
    // Setup MathJax
    MathJax.Hub.Config({
        tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });
    MathJax.Hub.Queue(function() {
        $(MathJax.Hub.getAllJax()).map(function(index, elem) {
            return(elem.SourceElement());
        }).parent().addClass('has-jax');
    });
    
    MathJax.Hub.Configured();
</script><!--     <script src="http://gnab.github.io/remark/downloads/remark-0.6.0.min.js" type="text/javascript">
    </script>
    <script type="text/javascript">
      var slideshow = remark.create({highlightStyle: 'monokai'});
    </script>
 -->  </body>
</html>